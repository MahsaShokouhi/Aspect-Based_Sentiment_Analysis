{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f45YrjGAYnRh"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3v9Mey1YZsT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from itertools import chain\n",
        "from collections import Counter\n",
        "\n",
        "from gensim import models\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS, remove_stopwords\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "import spacy\n",
        "import en_core_web_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2dLnIhxYtCj"
      },
      "source": [
        "# Define functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sO46JQVBYtog"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text, vectorizer=None):\n",
        "    '''Preprocess a text for topic modeling or aspect identification'''\n",
        "    if vectorizer: # used for NMF and supervised model\n",
        "        processed = vectorizer.transform([text])\n",
        "    else: # used for LDA    \n",
        "        text = remove_stopwords(text)\n",
        "        tokens = simple_preprocess(text)\n",
        "        tokens_lem = [WordNetLemmatizer().lemmatize(token, pos='v') for token in tokens]\n",
        "        processed = [token for token in tokens_lem if len(token) > 3]\n",
        "    return processed\n",
        "\n",
        "\n",
        "def get_main_topic(processed_text, model, topics_names, model_type='NMF'):\n",
        "    ''' Predict the dominant topic in a text'''\n",
        "    if model_type == 'LDA':\n",
        "        bow_vector = model.id2word.doc2bow(processed_text)\n",
        "        topics_scores = model[bow_vector]\n",
        "        dominant_topic, _ = sorted(topics_scores, \n",
        "                                   key=lambda tup: tup[1], \n",
        "                                   reverse=True)[0]\n",
        "    else:\n",
        "        scores = model.transform(processed_text)\n",
        "        scores = scores.reshape(-1)\n",
        "        dominant_topic = np.argsort(scores)[-1]\n",
        "    return topics_names[dominant_topic]\n",
        "\n",
        "\n",
        "def get_sentiment(text):\n",
        "    '''return the sentiment. ouput: positive/negative/neutral'''\n",
        "    scores = sia.polarity_scores(text)\n",
        "    if scores['compound'] > 0:\n",
        "        return 'positive'\n",
        "    elif scores['compound'] < 0:\n",
        "        return 'negative'\n",
        "    else:\n",
        "        return 'neutral'\n",
        "\n",
        "\n",
        "def get_descriptors(text):\n",
        "    '''get adjectives for a subject/noun'''\n",
        "    \n",
        "    def is_adjective(token):\n",
        "        '''return whether or not a token is an adjective.'''\n",
        "        return token.dep_ == 'amod' or token.pos_ == 'ADJ'\n",
        "    \n",
        "    def get_children(token):\n",
        "        '''get a list reprsenting all adjectives that are either first \n",
        "        or second order children of a given token.'''\n",
        "        first_ch = [child for child in token.children \n",
        "                    if child.pos_ not in ['AUX', 'VERB']]\n",
        "        second_ch = [list(ch.children) for ch in first_ch]\n",
        "        second_ch = list(chain.from_iterable(second_ch))  # convert to 1D list\n",
        "        return first_ch + second_ch \n",
        "    \n",
        "    subjects_descriptors = {}\n",
        "    for token in nlp(text):\n",
        "        # adjectives for subjects\n",
        "        if token.dep_ == 'nsubj' and token.pos_ != 'PRON':\n",
        "            descriptors = []\n",
        "            # descriptive adjectives\n",
        "            adjectives = [child for child in get_children(token) \n",
        "                          if is_adjective(child)]\n",
        "            descriptors.extend(adjectives)\n",
        "            # predicate adjectives (through a linking verb)\n",
        "            if token.head.pos_ in ['AUX', 'VERB']:\n",
        "                descriptors.extend([child for child in get_children(token.head)\n",
        "                                    if is_adjective(child)])\n",
        "            descriptors = list(set(descriptors))\n",
        "            subjects_descriptors[token] = descriptors\n",
        "        # adjectives for non-subject nouns\n",
        "        elif token.pos_ in ['NOUN', 'PROPN']:\n",
        "            subjects_descriptors[token] = [child for child in get_children(token) \n",
        "                                           if is_adjective(child)]\n",
        "        else:\n",
        "            continue\n",
        "    return subjects_descriptors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Define/load parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8FRVM52swzsV"
      },
      "outputs": [],
      "source": [
        "# create SentimentIntensityAnalyzer object\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# load the nlp model for POS and dependency tagging\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "# Define mapping between aspects or topics and their indices\n",
        "aspects = ['food', 'menu', 'service', 'place', 'price', 'miscellaneous', \n",
        "          'staff', 'ambience']\n",
        "\n",
        "ldaTopic_to_aspect = {\n",
        "    0: [],\n",
        "    1: ['service'],\n",
        "    2: ['staff'],\n",
        "    3: [],\n",
        "    4: ['service', 'ambience'],\n",
        "    5: ['menu'],\n",
        "    6: ['price'],\n",
        "    7: []\n",
        "}\n",
        "\n",
        "nmf_fnTopic_to_aspect = {\n",
        "    0: [],\n",
        "    1: ['staff'],\n",
        "    2: ['menu'],\n",
        "    3: ['place'],\n",
        "    4: [],\n",
        "    5: [],\n",
        "    6: ['staff'], \n",
        "    7: ['service']\n",
        "}\n",
        "\n",
        "nmf_klTopic_to_aspect = {\n",
        "    0: ['price', 'food'],\n",
        "    1: ['staff'],\n",
        "    2: ['menu'],\n",
        "    3: ['place', 'ambience'],\n",
        "    4: [],\n",
        "    5: [],\n",
        "    6: [],\n",
        "    7: ['service']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load saved models\n",
        "classifier = joblib.load('../models/classifier.pkl')\n",
        "vectorizer = joblib.load('../models/vectorizer.pkl')\n",
        "nmf_fn = joblib.load('../models/nmf_fn.pkl')\n",
        "nmf_kl = joblib.load('../models/nmf_kl.pkl')\n",
        "lda_model = models.LdaModel.load('../models/lda.model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwN_pRoMaxou"
      },
      "source": [
        "# Analysis pipeline\n",
        "\n",
        "### 1. Preprocess the input text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BA67MFRYZomC"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['This place is great! Atmosphere is chill and cool but the staff is also really friendly',\n",
              " 'They know what they’re doing and what they’re talking about, and you can tell making the customers happy is their main priority',\n",
              " 'Food is pretty good, some italian classics and some twists, and for their prices it’s 100% worth it']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = 'This place is great! Atmosphere is chill and cool but the staff is also really friendly. They know what they’re doing and what they’re talking about, and you can tell making the customers happy is their main priority. Food is pretty good, some italian classics and some twists, and for their prices it’s 100% worth it.'\n",
        "\n",
        "# Split the text into phrases\n",
        "phrases = [txt.strip() for txt in text.split('.') if len(txt) > 0]\n",
        "phrases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Identify the main aspect(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This place is great! Atmosphere is chill and cool but the staff is also really friendly\n",
            "main topics: ['miscellaneous']\n",
            "\n",
            "They know what they’re doing and what they’re talking about, and you can tell making the customers happy is their main priority\n",
            "main topics: ['staff']\n",
            "\n",
            "Food is pretty good, some italian classics and some twists, and for their prices it’s 100% worth it\n",
            "main topics: ['food']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for phrase in phrases:\n",
        "    # Text processing\n",
        "    preprocessed = preprocess_text(phrase, vectorizer=vectorizer)\n",
        "    preprocessed_lda = preprocess_text(phrase, vectorizer=None)\n",
        "    \n",
        "    # identify aspects using all models and concatenate them\n",
        "    topics_full = []\n",
        "    # supervised model\n",
        "    label = classifier.predict(preprocessed)       \n",
        "    aspects_pred = [aspects[i] for i, is_predicted in enumerate(label.reshape(-1)) \n",
        "                    if is_predicted]\n",
        "    topics_full.extend(aspects_pred)\n",
        "    # NMF with Frobenius norm\n",
        "    topics = get_main_topic(preprocessed, nmf_fn, nmf_fnTopic_to_aspect, \n",
        "                            model_type='NMF')\n",
        "    if len(topics) == 0:\n",
        "        topics = ['miscellaneous']\n",
        "    topics_full.extend(topics)\n",
        "    # NMF with Kullback-Leibler divergence\n",
        "    topics = get_main_topic(preprocessed, nmf_kl, nmf_klTopic_to_aspect, \n",
        "                            model_type='NMF')\n",
        "    if len(topics) == 0:\n",
        "        topics = ['miscellaneous']\n",
        "    topics_full.extend(topics)\n",
        "    # LDA\n",
        "    topics = get_main_topic(preprocessed_lda, lda_model, ldaTopic_to_aspect, \n",
        "                            model_type='LDA')\n",
        "    if len(topics) == 0:\n",
        "        topics = ['miscellaneous']\n",
        "    topics_full.extend(topics)\n",
        "    # Select topic with highest vote\n",
        "    counts = Counter(topics_full)\n",
        "    main_topics = [topic for (topic, count) in counts.items() \n",
        "                   if counts[topic] == max(counts.values())]\n",
        "    \n",
        "    # output\n",
        "    print(phrase)\n",
        "    print(f'main topics: {main_topics}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPFa3ysRbW26"
      },
      "source": [
        "### 3. Sentiment analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Z74JBgr4bV-9",
        "outputId": "cb08fa26-caf1-4807-ec3e-12a1d9a83adf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This place is great! Atmosphere is chill and cool but the staff is also really friendly\n",
            "sentiment: positive\n",
            "\n",
            "They know what they’re doing and what they’re talking about, and you can tell making the customers happy is their main priority\n",
            "sentiment: positive\n",
            "\n",
            "Food is pretty good, some italian classics and some twists, and for their prices it’s 100% worth it\n",
            "sentiment: positive\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for phrase in phrases:\n",
        "    print(phrase)\n",
        "    print(f'sentiment: {get_sentiment(phrase)}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaD2iK-Ec9eK"
      },
      "source": [
        "### 4. Extracting subjects and descriptors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcqWUcGBlZYl",
        "outputId": "e4cf4369-72eb-4bc8-c601-f9b4f8e712e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This place is great! Atmosphere is chill and cool but the staff is also really friendly\n",
            "subjects: [place, Atmosphere, chill, staff]\n",
            "descriptors: [great, cool, friendly]\n",
            "\n",
            "They know what they’re doing and what they’re talking about, and you can tell making the customers happy is their main priority\n",
            "subjects: [customers, priority]\n",
            "descriptors: [main]\n",
            "\n",
            "Food is pretty good, some italian classics and some twists, and for their prices it’s 100% worth it\n",
            "subjects: [Food, classics, twists, prices, %]\n",
            "descriptors: [good, italian]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for phrase in phrases:\n",
        "    subjects_descriptors = get_descriptors(phrase)\n",
        "    subjects = sorted(set(subjects_descriptors.keys()))\n",
        "    descriptors = sorted(\n",
        "        set(chain.from_iterable(subjects_descriptors.values()))\n",
        "        )\n",
        "    print(phrase)\n",
        "    print(f'subjects: {subjects}')\n",
        "    print(f'descriptors: {descriptors}\\n')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "pipeline.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
